{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86a3ef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from random import choice\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from os.path import isfile\n",
    "import sys\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02158ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "social_dims = ['baseline','support', 'knowledge', 'conflict', 'similarity', 'fun', 'status', 'trust', 'identity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5c55c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_convincing_arguments(social_dim, return_counts=False):\n",
    "    \"\"\"\n",
    "    Given a social dimension, parse all the arguments generated by the corresponding Convincer,\n",
    "    return the amount of arguments which convinced the Skeptic.\n",
    "    \"\"\"\n",
    "    convincing_arguments = []\n",
    "    files_to_check = os.listdir(f\"../conversation_generation/convs/convs_{social_dim}/\")\n",
    "    for filename in files_to_check:\n",
    "        with open(f\"../conversation_generation/convs/convs_{social_dim}/{filename}\", \"r\") as f:\n",
    "            conv = f.read().strip()\n",
    "            conv_hist = re.split(pattern = \"(Convincer:|Skeptic:)\", string = conv)\n",
    "            convincer_argument = conv_hist[6].strip()\n",
    "            skeptic_opinion = conv_hist[-1].strip()\n",
    "            opinion_signal = str.lower(skeptic_opinion.split(\" \")[0])\n",
    "            if \"yes\" in opinion_signal:\n",
    "                convincing_arguments.append((convincer_argument,f\"convs_{social_dim}/{filename}\"))\n",
    "    return convincing_arguments\n",
    "\n",
    "\n",
    "convincing_arguments_by_dim = {social_dim: get_convincing_arguments(social_dim) for social_dim in social_dims}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cae3393c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline 8\n",
      "support 64\n",
      "knowledge 22\n",
      "conflict 3\n",
      "similarity 17\n",
      "fun 20\n",
      "status 42\n",
      "trust 65\n",
      "identity 7\n"
     ]
    }
   ],
   "source": [
    "# The amount of convincing arugments per dimension\n",
    "for dim in social_dims:\n",
    "    print(dim,len(list(set(convincing_arguments_by_dim[dim]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2b9f1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_arguments_for_matches(convincing_arguments_by_dim=convincing_arguments_by_dim):\n",
    "    \"\"\"\n",
    "    Go through all the pairs of social dimensons, \n",
    "    and select 5 convincing arguments from each randomly.\n",
    "    Returns the file of matchups which will be used to create the MTurk batch.\n",
    "    \"\"\"\n",
    "    counter = 0\n",
    "    text_to_id = {}\n",
    "    matches = defaultdict(list)\n",
    "\n",
    "    for _ in range(5):\n",
    "        for dim1 in social_dims:\n",
    "            for dim2 in social_dims:\n",
    "                if dim1 != dim2 and f\"{dim2},{dim1}\" not in matches: # Do not pair itself, and avoid repeat matches\n",
    "                    dict_to_append = {}\n",
    "                    for i,dim_iter in enumerate([dim1,dim2]):\n",
    "                        argument,filename = choice(convincing_arguments_by_dim[dim_iter])\n",
    "                        if argument in text_to_id:\n",
    "                            id1 = text_to_id[argument]\n",
    "                        else:\n",
    "                            text_to_id[argument] = counter\n",
    "                            id1 = counter\n",
    "                            counter +=1\n",
    "\n",
    "                        dict_to_append[f'arg{i+1}'] = {'text':argument,'id':id1,'filename':filename}\n",
    "                    matches[f\"{dim1},{dim2}\"].append(deepcopy(dict_to_append))\n",
    "    return dict(matches)\n",
    "\n",
    "if isfile('total_5_arguments_for_mturk.json'):\n",
    "    with open('total_5_arguments_for_mturk.json') as matchfile:\n",
    "        matches = json.load(matchfile)\n",
    "else:\n",
    "    matches = select_arguments_for_matches()\n",
    "    with open('total_5_arguments_for_mturk.json','w') as f:\n",
    "        json.dump(matches,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a64769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbb42204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_to_text(matches):\n",
    "    id_to_text = {}\n",
    "    text_to_id = {}\n",
    "    for dim in matches:\n",
    "        for match in matches[dim]:\n",
    "            for arg in match['arg1'],match['arg2']:\n",
    "                id_to_text[arg['id']] = arg['text']\n",
    "                text_to_id[arg['text']] = arg['id']\n",
    "    return id_to_text, text_to_id\n",
    "id_to_text,text_to_id = get_id_to_text(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "439468ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_newline_every_x_chars(text, max_len):\n",
    "    \"\"\"\n",
    "    Helper function for creating readable SVGs which aren't infinitely wide.\n",
    "    \"\"\"\n",
    "    words = text.replace('\\n',' \\n ').split(\" \")\n",
    "    modified_text = \"\"\n",
    "    count = 0\n",
    "    \n",
    "    for i, word in enumerate(words):\n",
    "        if not word:\n",
    "            continue\n",
    "        if word == \"\\n\":\n",
    "            modified_text += f\"{word}\"\n",
    "            count = 0  # Reset count on encountering a normal line break\n",
    "        elif (len(word) + count) > max_len:\n",
    "            modified_text += f\"\\n{word} \" \n",
    "            count = len(word)+1\n",
    "        else:\n",
    "            modified_text += f\"{word} \"\n",
    "            count += len(word)+1\n",
    "    \n",
    "    return modified_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f125f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_svgs(text):\n",
    "    \"\"\"Given a text, create an SVG image which can be displayed on MTurk\"\"\"\n",
    "    template = \"\"\"\n",
    "     <svg viewBox=\"0 0 700 {img_height}\" xmlns=\"http://www.w3.org/2000/svg\">\n",
    "  <style>\n",
    "    .small {{\n",
    "      font: 20px sans-serif;\n",
    "    }}\n",
    "    .heavy {{\n",
    "      font: bold 30px sans-serif;\n",
    "    }}\n",
    "\n",
    "  </style>\n",
    "\n",
    "<rect x=\"0\" y=\"0\" width=\"700\" height=\"{img_height}\" fill=\"white\"/>\n",
    "  <text x=\"0\" y=\"35\" class=\"small\">\n",
    "  {text_template}\n",
    "  </text>\n",
    "  </svg>\"\"\"\n",
    "    text_template =   \"\"\"<tspan x=\"10\" dy=\"1.2em\">\n",
    "     {new_text}\n",
    "  </tspan>\"\"\"\n",
    "    pieces_of_text = []\n",
    "    text = insert_newline_every_x_chars(text,57)\n",
    "    lines = text.split('\\n')\n",
    "    for line in lines:\n",
    "        pieces_of_text.append(text_template.format(new_text=line))\n",
    "        \n",
    "    full_svg = template.format(text_template = \"\\n\".join(pieces_of_text),img_height=len(lines)*26)\n",
    "    return full_svg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "d1fa2045",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text_id, text in sorted(id_to_text.items(),key=lambda x:x[0]):\n",
    "    text_new = text.split('\\n_____')[0]\n",
    "\n",
    "    with open(f'svg_img/image{text_id}.svg', 'w') as f:\n",
    "        print(make_svgs(text_new),file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2587e64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir('control_samples'):\n",
    "    with open(f'control_samples/{file}') as f:\n",
    "        text = f.read()\n",
    "        with open(f'svg_img/image-{file.replace(\".\",\"-\").replace(\"_\",\"-\")}.svg', 'w') as g:\n",
    "            print(make_svgs(text),file=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f07cebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('total_5_arguments_for_mturk.json') as matchfile:\n",
    "    matches = json.load(matchfile)\n",
    "print(len(matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a70737",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
